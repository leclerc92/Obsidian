
## *Pour les problème d’optimisation :* 


fonction strictement convexe = un sais qu’un minimum existe 

Le calcul de la [[Dérivées]] seconde permet d’observer la convexité d’une fonction

Lorsque la dérivée est nul en un point cela peut être le maximum ou le minimum de la fonction —> la forme de la fonction indiquera alors dans quel cas on se trouve


**Forme d’une fonction convexe**


```handwritten-ink
{
	"versionAtEmbed": "0.3.4",
	"filepath": "Ink/Writing/2025.10.1 - 9.13am.writing"
}
```


Convexité d’un domaine : si je prends deux point d’un domaine, la droite qui les relies doit être entièrement dans le domaine

```handwritten-ink
{
	"versionAtEmbed": "0.3.4",
	"filepath": "Ink/Writing/2025.9.25 - 11.18am.writing"
}
```
> [!exemple] exemples de fonctions convexes : 
> $$f(x) = ax + b$$
>  $$f(x) = x^2$$$$f(x) = e^x$$

### Condition nécéssaire d’optimalité

Les conditions nécessaire d’optimalité donnent les conditions nécessairement vérifiées par un minimum local x de f.
Deux condition pour vérifier :
- **Condition du premier ordre** —> lié au gradient
- **Condition du second ordre** —> lié à la [[Matrice hessienne]]

**Point critiques** ou **points stationnaires** sont les points pour qui la dérivée de la fonction en ces points = 0.


Exemple d’un problème d’optimisation (slide 62) :
1) Trouver les points stationnaires